{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90572e29",
   "metadata": {},
   "source": [
    "# ISPA - SearchLight\n",
    "Script adapted from: https://github.com/SylvainTakerkart/inter_subject_pattern_analysis/tree/master/fmri_data\n",
    "\n",
    "Original paper: https://doi.org/10.1016/j.neuroimage.2019.116205"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd30d43",
   "metadata": {},
   "source": [
    "This script demonstrates how to use the searchlight implementation\n",
    "available in nilearn to perform group-level decoding using an\n",
    "inter-subject pattern analysis (ISPA) scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7516cd",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e895617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as op\n",
    "import re\n",
    "import glob\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from nilearn.image import math_img, new_img_like, concat_imgs, resample_to_img, clean_img\n",
    "from nilearn.decoding import SearchLight\n",
    "from nilearn.image import math_img, new_img_like, concat_imgs, resample_to_img\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.masking import apply_mask, compute_epi_mask\n",
    "from nilearn import plotting\n",
    "\n",
    "import nibabel as n\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import random\n",
    "import csv\n",
    "import time  # Import the time module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e62fa7",
   "metadata": {},
   "source": [
    "## Opening files to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f8414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the path to your GLM directory\n",
    "data_dir = '/projetos/PRJ1901_AMID/03_PROCS/Postnatal_Affective_Dataset/PROC_DATA/derivatives/GLM'\n",
    "\n",
    "# getting a full list of available subjects\n",
    "files = os.listdir(data_dir)\n",
    "pattern = r'sub-(\\d+)_LSA'\n",
    "subject_numbers = [re.search(pattern, file_name).group(1) for file_name in files if re.search(pattern, file_name)]\n",
    "\n",
    "# List of subjects to include, empty means include all\n",
    "subjects_to_include = ['3120','0196']  # Fill with subject identifiers or leave empty to include all\n",
    "\n",
    "beta_flist = []\n",
    "y = []\n",
    "subj_vect = []\n",
    "runs = []\n",
    "        \n",
    "# Create lists from beta map filenames in 'beta_flist', labels in 'y', and subject numbers in 'subj_vect'.\n",
    "for subject_number in subject_numbers:\n",
    "    # If subjects_to_include is empty or subject_number is in the list, process the subject\n",
    "    if not subjects_to_include or subject_number in subjects_to_include:\n",
    "        subject_directory = os.path.join(data_dir, f'sub-{subject_number}_LSA')\n",
    "\n",
    "        # List beta map files for the current subject\n",
    "        beta_map_files = glob.glob(os.path.join(subject_directory, f'sub-{subject_number}_run*_*.nii.gz'))\n",
    "        beta_map_files.sort()\n",
    "        beta_flist.extend(beta_map_files)\n",
    "\n",
    "        # Extract the label from the beta map filename\n",
    "        for beta_map_file in beta_map_files:\n",
    "            label = beta_map_file.split('_')[-3]  # Assumes label is the third last part of the filename\n",
    "            if \"InfOther\" in label:  # Adjust labels to consider Own vs. Other (irrelevant to valence)\n",
    "                label = \"Other\"\n",
    "            elif \"InfOwn\" in label:\n",
    "                label = \"Own\"\n",
    "            y.append(label)\n",
    "            subj_vect.append(subject_number)\n",
    "\n",
    "        # Extract run info from the beta map filename (to be used in standardization)\n",
    "        for beta_map_file in beta_map_files:\n",
    "            run = beta_map_file.split('_')[-4]  # Assumes run is the fourth last part of the filename\n",
    "            runs.append(run)\n",
    "\n",
    "## STANDARDIZATIOIN (per run and subject)\n",
    "\n",
    "# read image data\n",
    "print(\"Reading beta maps from all the subjects...\")\n",
    "\n",
    "fmri_nii_dict = {}\n",
    "\n",
    "for beta_path in beta_flist:\n",
    "    parts = re.split(r'[/_]', beta_path)\n",
    "    subj = parts[-6]\n",
    "    run = 'run-'+parts[-4]\n",
    "    condition = parts[-3]\n",
    "    beta = parts[-2]\n",
    "    \n",
    "    image = nb.load(beta_path)\n",
    "    \n",
    "    # Check if the subject already exists in the dictionary\n",
    "    if subj in fmri_nii_dict:\n",
    "        # If the run exists for the subject, append the data to the existing list\n",
    "        if run in fmri_nii_dict[subj]:\n",
    "            fmri_nii_dict[subj][run].append({'condition': condition, 'beta': beta, 'image': image})\n",
    "        # If the run doesn't exist, create a new entry for the run\n",
    "        else:\n",
    "            fmri_nii_dict[subj][run] = [{'condition': condition,'beta': beta, 'image': image}]\n",
    "    # If the subject doesn't exist, create a new entry for the subject and run\n",
    "    else:\n",
    "        fmri_nii_dict[subj] = {run: [{'condition': condition,'beta': beta, 'image': image}]}\n",
    "\n",
    "# Printing the created dictionary\n",
    "for subj, subj_value in fmri_nii_dict.items():\n",
    "    for run, run_value in subj_value.items():\n",
    "        print(f\"Subject: {subj}, Run: {run}\")\n",
    "        for item in run_value:\n",
    "            print(item)\n",
    "        print('\\n')\n",
    "        \n",
    "## CONCATENATE BETAS IMAGES ##\n",
    "\n",
    "concat_imgs_dict = {}\n",
    "concat_imgs_stand_dict = {}\n",
    "\n",
    "# Concatenating the images for the same run and subject\n",
    "for subj, subj_value in fmri_nii_dict.items():\n",
    "    for run, run_value in subj_value.items():\n",
    "        images_to_concat = [item['image'] for item in run_value]\n",
    "        concatenated_image = concat_imgs(images_to_concat)\n",
    "        print(f\"Subject: {subj}, Run: {run}, Concatenated Beta Images Shape: {concatenated_image.shape}\")\n",
    "        \n",
    "        # Adding concatenated image to the concat_imgs_dict\n",
    "        if subj in concat_imgs_dict:\n",
    "            concat_imgs_dict[subj][run] = concatenated_image\n",
    "        else:\n",
    "            concat_imgs_dict[subj] = {run: concatenated_image}\n",
    "\n",
    "        # Standardized beta maps with clean_img()\n",
    "        stand_image = clean_img(concatenated_image, standardize=True, detrend=False)\n",
    "        print(f\"Subject: {subj}, Run: {run}, Concatenated Standardized Beta Images Shape: {stand_image.shape}\")\n",
    "        \n",
    "        # Adding standardized image to the concat_imgs_stand_dict\n",
    "        if subj in concat_imgs_stand_dict:\n",
    "            concat_imgs_stand_dict[subj][run] = stand_image\n",
    "        else:\n",
    "            concat_imgs_stand_dict[subj] = {run: stand_image}\n",
    "            \n",
    "# Concatenate all subjects #\n",
    "\n",
    "all_images_to_concat = []\n",
    "\n",
    "for subj, subj_value in concat_imgs_stand_dict.items():\n",
    "    for run, stand_image in subj_value.items():\n",
    "        all_images_to_concat.append(stand_image)\n",
    "\n",
    "all_betas_stand = concat_imgs(all_images_to_concat) \n",
    "\n",
    "print(f\"All Betas Stand Shape: {all_betas_stand.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaa55be",
   "metadata": {},
   "source": [
    "# Setting up for leave-one-subject-out cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb510ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up leave-one-subject-out cross-validation\n",
    "loso = LeaveOneGroupOut()\n",
    "unique_subjects = np.unique(subj_vect)\n",
    "n_splits = loso.get_n_splits(groups=unique_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6ef87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output directory\n",
    "output_dir = \"/projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/ISPA_SearchLight_TB_permut_test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Calculate the chance level\n",
    "chance_level = 1. / len(np.unique(y))\n",
    "\n",
    "# reading brain mask\n",
    "brain_mask = nb.load(\"/projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/brain_mask.nii.gz\")\n",
    "\n",
    "# Check whether mask and Betas are in the same space and resample if necessary\n",
    "beta_img = nb.load(beta_map_files[0])\n",
    "\n",
    "if not beta_img.shape == brain_mask.shape:\n",
    "    brain_mask = resample_to_img(brain_mask, beta_img, interpolation='nearest')\n",
    "    print(\"Brain mask resampled to match betas images.\")\n",
    "    \n",
    "whole_brain = 1\n",
    "\n",
    "if whole_brain == 1:\n",
    "    print(\"running whole-brain classification\")\n",
    "else:\n",
    "    # open ROI mask if not  whole-brain\n",
    "    roi_mask_nii = nb.load(\"/projetos/PRJ1901_AMID/03_PROCS/Postnatal_Affective_Dataset/BIDS_Nilearn/2ndLvPilotSPACE_Binar_NAccBrian_OFC_Septal.nii\")\n",
    "    # Check whether ROI and Betas are in the same space and resample if necessary\n",
    "    if not beta_img.shape == roi_mask_nii.shape:\n",
    "        roi_mask_nii = resample_to_img(roi_mask_nii, beta_img, interpolation='nearest')\n",
    "        print(\"ROI mask resampled to match the beta images.\")\n",
    "        print(\"running ROI classification\")\n",
    "        \n",
    "# running searchlight decoding\n",
    "searchlight_radius = 4\n",
    "n_jobs = -1\n",
    "y = np.array(y)\n",
    "single_split_path_list = []\n",
    "print(\"Launching cross-validation...\")\n",
    "\n",
    "for split_ind, (train_inds,test_inds) in enumerate(loso.split(subj_vect,subj_vect,subj_vect)):\n",
    "    print(\"...split {:02d} of {:02d}\".format(split_ind+1, n_splits))\n",
    "    single_split = [(train_inds,test_inds)]\n",
    "    y_train = y[train_inds]\n",
    "    n_samples = len(y_train)\n",
    "    class_labels = np.unique(y_train)\n",
    "    clf = LogisticRegression()\n",
    "    if whole_brain == 1:\n",
    "        searchlight = SearchLight(mask_img = brain_mask,\n",
    "                                  process_mask_img = brain_mask,\n",
    "                              radius=searchlight_radius,\n",
    "                              n_jobs=n_jobs,\n",
    "                              verbose=0,\n",
    "                              cv=single_split,\n",
    "                              estimator=clf)\n",
    "    else:\n",
    "        searchlight = SearchLight(mask_img = brain_mask,\n",
    "                              radius=searchlight_radius,\n",
    "                              n_jobs=n_jobs,\n",
    "                              verbose=0,\n",
    "                              cv=single_split,\n",
    "                              estimator=clf,\n",
    "                              process_mask_img=roi_mask_nii)\n",
    "            \n",
    "    \n",
    "    searchlight.fit(all_betas_stand, y)\n",
    "    \n",
    "    print(\"...mapping the data (this takes a long time) and fitting the model in each sphere\")\n",
    "    \n",
    "    single_split_nii = new_img_like(brain_mask,searchlight.scores_ - chance_level)\n",
    "    single_split_path = op.join(output_dir, 'ispa_searchlight_accuracy_split{:02d}of{:02d}.nii'.format(split_ind+1,n_splits))\n",
    "    print('Saving score map for cross-validation fold number {:02d}'.format(split_ind+1))\n",
    "    single_split_nii.to_filename(single_split_path)\n",
    "    single_split_path_list.append(single_split_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df716a5",
   "metadata": {},
   "source": [
    "# Non-parametric Permutations with nilearn\n",
    "Originally it was performed with SnPM MATLAB toolbox to analyse the single-fold (for the inter-subject cross-validation of ISPA) accuracy maps, with 1000 permutations and a significance threshold (p<0,05, FWE corrected).\n",
    "Here, we are trying to do the same, but using nilearn.\n",
    "\n",
    "Original SnPM batch: https://github.com/SylvainTakerkart/inter_subject_pattern_analysis/blob/master/fmri_data/snpm_batch.m\n",
    "\n",
    "## Here we have tried to implement the permutatoin scheme suggested by Stelzer et al. 2013, by permuting labels for X searchlights per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5c0e8df7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain mask resampled to match betas images.\n",
      "running whole-brain classification\n",
      "Launching cross-validation...\n",
      "...split 01 of 02\n",
      "...within-subject permutation 01 of 2\n",
      "Saving permutation score map 001 for split 01\n",
      "Searchlight 1 completed in 88.34 seconds.\n",
      "...within-subject permutation 02 of 2\n",
      "Saving permutation score map 002 for split 01\n",
      "Searchlight 2 completed in 84.87 seconds.\n",
      "Split 1 completed in 173.21 seconds.\n",
      "...split 02 of 02\n",
      "...within-subject permutation 01 of 2\n",
      "Saving permutation score map 001 for split 02\n",
      "Searchlight 1 completed in 84.78 seconds.\n",
      "...within-subject permutation 02 of 2\n",
      "Saving permutation score map 002 for split 02\n",
      "Searchlight 2 completed in 85.51 seconds.\n",
      "Split 2 completed in 170.29 seconds.\n",
      "Total processing time: 343.50 seconds.\n"
     ]
    }
   ],
   "source": [
    "# output directory\n",
    "output_dir = \"/projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/ISPA_SearchLight_TB_permut_test/withinsubj_permut_test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Calculate the chance level\n",
    "chance_level = 1. / len(np.unique(y))\n",
    "\n",
    "# running searchlight decoding\n",
    "searchlight_radius = 4\n",
    "n_jobs = -1\n",
    "y = np.array(y)\n",
    "single_split_path_list = []\n",
    "\n",
    "# Number of permutations within subject\n",
    "n_permutations = 2\n",
    "\n",
    "# List to hold the timings\n",
    "timings = []\n",
    "\n",
    "# List to hold the mean accuracies per permutation and split\n",
    "mean_accs = []\n",
    "\n",
    "# reading brain mask\n",
    "brain_mask = nb.load(\"/projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/brain_mask.nii.gz\")\n",
    "\n",
    "# Check whether mask and Betas are in the same space and resample if necessary\n",
    "beta_img = nb.load(beta_map_files[0])\n",
    "\n",
    "if not beta_img.shape == brain_mask.shape:\n",
    "    brain_mask = resample_to_img(brain_mask, beta_img, interpolation='nearest')\n",
    "    print(\"Brain mask resampled to match betas images.\")\n",
    "    \n",
    "whole_brain = 1\n",
    "\n",
    "if whole_brain == 1:\n",
    "    print(\"running whole-brain classification\")\n",
    "else:\n",
    "    # open ROI mask if not  whole-brain\n",
    "    roi_mask = nb.load(\"/projetos/PRJ1901_AMID/03_PROCS/Postnatal_Affective_Dataset/BIDS_Nilearn/2ndLvPilotSPACE_Binar_NAccBrian_OFC_Septal.nii\")\n",
    "    # Check whether ROI and Betas are in the same space and resample if necessary\n",
    "    if not beta_img.shape == roi_mask.shape:\n",
    "        roi_mask = resample_to_img(roi_mask, beta_img, interpolation='nearest')\n",
    "        print(\"ROI mask resampled to match the beta images.\")\n",
    "        print(\"running ROI classification\")\n",
    "\n",
    "        \n",
    "# Initialize NiftiMasker with the brain mask, and fit it once\n",
    "nifti_masker = NiftiMasker(standardize=False,\n",
    "            mask_img=brain_mask,\n",
    "            memory_level=0,\n",
    "            smoothing_fwhm=None)\n",
    "\n",
    "nifti_masker.fit()        \n",
    "        \n",
    "        \n",
    "print(\"Launching cross-validation...\")\n",
    "total_start_time = time.time()  # Capture the start time of the entire process\n",
    "\n",
    "for split_ind, (train_inds,test_inds) in enumerate(loso.split(subj_vect,subj_vect,subj_vect)):\n",
    "    print(\"...split {:02d} of {:02d}\".format(split_ind+1, n_splits))\n",
    "    split_start_time = time.time()  # Start time for this split\n",
    "    \n",
    "    for permutation in range(n_permutations):\n",
    "        print(f\"...within-subject permutation {permutation+1:02d} of {n_permutations}\")\n",
    "        permutation_start_time = time.time()  # Start time for this permutation\n",
    "        \n",
    "        # Append the results to timing list\n",
    "        #timings.append({f\"Start time for split {split_ind+1}': split_start_time})\n",
    "        \n",
    "        # Shuffle y labels for this permutation\n",
    "        np.random.seed(permutation)  # Setting the seed for reproducibility\n",
    "        y_shuffled = np.random.permutation(y)\n",
    "\n",
    "        # Set up the classifier and searchlight with the shuffled labels\n",
    "        clf = LogisticRegression()\n",
    "        if whole_brain == 1:\n",
    "            searchlight = SearchLight(mask_img = brain_mask,\n",
    "                                  process_mask_img = brain_mask,\n",
    "                              radius=searchlight_radius,\n",
    "                              n_jobs=n_jobs,\n",
    "                              verbose=0,\n",
    "                              cv=single_split,\n",
    "                              estimator=clf)\n",
    "        else:\n",
    "            searchlight = SearchLight(mask_img = brain_mask,\n",
    "                                  process_mask_img = roi_mask,\n",
    "                              radius=searchlight_radius,\n",
    "                              n_jobs=n_jobs,\n",
    "                              verbose=0,\n",
    "                              cv=single_split,\n",
    "                              estimator=clf)\n",
    "        \n",
    "        searchlight_start_time = time.time()  # Start time for this searchlight\n",
    "        # Fit the model with shuffled labels\n",
    "        searchlight.fit(all_betas_stand, y_shuffled)\n",
    "\n",
    "        # Compute accuracy map and subtract chance level\n",
    "        accuracy_map = searchlight.scores_ - chance_level\n",
    "\n",
    "        # Save the accuracy map for this permutation and split\n",
    "        single_split_nii = new_img_like(brain_mask, accuracy_map)\n",
    "        output_filename = f'split_{split_ind+1:02d}_permutation_{permutation+1:03d}_accuracy.nii'\n",
    "        single_split_path = os.path.join(output_dir, output_filename)\n",
    "        print(f'Saving permutation score map {permutation+1:03d} for split {split_ind+1:02d}')\n",
    "        single_split_nii.to_filename(single_split_path)\n",
    "        \n",
    "        ####INCLUDE MASK TO GET ONLY BRAIN VALUES!!!! ######\n",
    "    \n",
    "        # Apply the mask to your statistical image\n",
    "        masked_data = apply_mask(single_split_nii, nifti_masker.mask_img_)\n",
    "    \n",
    "        # Get the shape of the statistical image\n",
    "        map_data = single_split_nii.get_fdata()\n",
    "        stat_shape = map_data.shape\n",
    "\n",
    "        # Create an empty array of the same shape as the statistical image\n",
    "        masked_img_data = np.zeros(stat_shape)\n",
    "\n",
    "        # Fill the masked_img_data with masked_data\n",
    "        masked_img_data[nifti_masker.mask_img_.get_fdata() > 0] = masked_data\n",
    "        # create masked nii\n",
    "        masked_img = nib.Nifti1Image(masked_img_data, affine=single_split_nii.affine)\n",
    "        #save masked image\n",
    "        output_filename_mask = f'split_{split_ind+1:02d}_permutation_{permutation+1:03d}_accuracy_MASKED.nii'\n",
    "        single_split_path_masked = os.path.join(output_dir, output_filename_mask)\n",
    "        masked_img.to_filename(single_split_path_masked)\n",
    "        \n",
    "        # Append the split number, permutation number, and mean accuracy to mean_accs\n",
    "        mean_accs.append({\n",
    "            \"Split Number\": split_ind + 1,\n",
    "            \"Permutation Number\": permutation + 1,\n",
    "            \"Mean Accuracy\": (np.mean(masked_data))\n",
    "        })\n",
    "        \n",
    "        # Print duration for this searchlight\n",
    "        searchlight_end_time = time.time()\n",
    "    \n",
    "        print(f\"Searchlight {permutation+1} completed in {searchlight_end_time - searchlight_start_time:.2f} seconds.\")\n",
    "        # Append the results to timing list\n",
    "        timings.append({f\"Searchlight {permutation+1}: {searchlight_end_time - searchlight_start_time:.2f}\"})\n",
    "        \n",
    "    # Print duration for this split\n",
    "    split_end_time = time.time()\n",
    "    print(f\"Split {split_ind+1} completed in {split_end_time - split_start_time:.2f} seconds.\")\n",
    "    timings.append({f\"Split {split_ind+1}: {split_end_time - split_start_time:.2f}\"})\n",
    "\n",
    "# Print the total duration\n",
    "total_end_time = time.time()\n",
    "print(f\"Total processing time: {total_end_time - total_start_time:.2f} seconds.\")\n",
    "timings.append({f\"Total processing time: {total_end_time - total_start_time:.2f}\"})\n",
    "\n",
    "new_df = pd.DataFrame(timings)\n",
    "new_df.to_csv('timings_all.csv', index=False)\n",
    "\n",
    "# Create a DataFrame from mean_accs\n",
    "mean_accs_df = pd.DataFrame(mean_accs)\n",
    "\n",
    "# Save to CSV\n",
    "mean_accs_csv_path = os.path.join(output_dir, \"null_array_100_perm.csv\")\n",
    "mean_accs_df.to_csv(mean_accs_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47e862-1572-4927-b4da-a2a52d16c888",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Randomly select one accuracy map per subject and average (repeat 10n5 x).\n",
    "\n",
    "## Pool of 10n5 chance group accuracy maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f41e50e2-098e-4f2f-a2cb-35d877402b11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain mask resampled to match input mages.\n",
      "Total processing time: 3.32 seconds.\n",
      "Timings saved to /projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/ISPA_SearchLight_TB_permut_test/withinsubj_permut_test/permu_mean_group_acc_maps_test/timings.csv\n",
      "Null distribution saved to /projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/ISPA_SearchLight_TB_permut_test/withinsubj_permut_test/permu_mean_group_acc_maps_test/null_distribution_group_mean.csv\n"
     ]
    }
   ],
   "source": [
    "# Define input and output directories\n",
    "input_dir = \"/projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/ISPA_SearchLight_TB_permut_test/withinsubj_permut_test\"\n",
    "output_dir = os.path.join(input_dir, \"permu_mean_group_acc_maps_test\")\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to extract unique split identifiers based on existing files in directory\n",
    "def get_unique_identifiers(directory, pattern):\n",
    "    files = glob.glob(os.path.join(directory, pattern))\n",
    "    unique_ids = set()\n",
    "    for file in files:\n",
    "        match = re.search(r\"split_(\\d+)_permutation_(\\d+)_accuracy\\.nii\", file)\n",
    "        if match:\n",
    "            unique_ids.add(match.group(1))\n",
    "    return list(unique_ids)\n",
    "\n",
    "# Use the function to get a list of unique split identifiers\n",
    "split_identifiers = get_unique_identifiers(input_dir, \"split_*_permutation_*_accuracy.nii\")\n",
    "\n",
    "# fix identifier for testing\n",
    "split_identifiers= ['01','02']\n",
    "\n",
    "# Preload maps paths for each split identifier\n",
    "split_maps_paths = {}\n",
    "for split_identifier in split_identifiers:\n",
    "    pattern = os.path.join(input_dir, f\"split_{split_identifier}_permutation_*_accuracy.nii\")\n",
    "    split_maps_paths[split_identifier] = glob.glob(pattern)\n",
    "\n",
    "# Load an example NIfTI image to get the shape and affine\n",
    "example_img_path = split_maps_paths[split_identifiers[0]][0]\n",
    "example_img = nib.load(example_img_path)\n",
    "\n",
    "# load brain mask for computation of mean values considering only \"brain voxels\"\n",
    "brain_mask = nb.load(\"/projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/brain_mask.nii.gz\")\n",
    "\n",
    "if not selected_map.shape == brain_mask.shape:\n",
    "    brain_mask = resample_to_img(brain_mask, selected_map, interpolation='nearest')\n",
    "    print(\"Brain mask resampled to match input mages.\")\n",
    "\n",
    "# Initialize NiftiMasker with the brain mask, and fit it once\n",
    "nifti_masker = NiftiMasker(standardize=False,\n",
    "            mask_img=brain_mask,\n",
    "            memory_level=0,\n",
    "            smoothing_fwhm=None)\n",
    "\n",
    "nifti_masker.fit()\n",
    "    \n",
    "n_iterations = 10\n",
    "\n",
    "wholebrain = 1\n",
    "\n",
    "def perform_iteration(iteration, output_dir, nifti_masker, split_maps_paths):\n",
    "    \"\"\"\n",
    "    Performs a single iteration of processing, which includes selecting one map per subject/split,\n",
    "    applying a brain mask, accumulating the masked data, and computing the mean across the selected maps.\n",
    "    \n",
    "    Parameters:\n",
    "    - iteration (int): The current iteration number. Used for output file naming and tracking.\n",
    "    - output_dir (str): The directory where output files will be saved.\n",
    "    - brain_mask (numpy.ndarray): A boolean array where True values indicate voxels within the brain.\n",
    "                                  This mask is applied to each map to focus analysis on brain voxels only.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing:\n",
    "      - The iteration number.\n",
    "      - The duration it took to complete the iteration.\n",
    "      - The paths of the selected maps for this iteration.\n",
    "      - The mean accuracy across the selected maps, considering only brain voxels.\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()  # Start timing the iteration\n",
    "    \n",
    "    # Initialize a 3D array to accumulate masked data across all selected maps\n",
    "    sum_of_masked_data = np.zeros(example_img.shape)\n",
    "    mask_voxels_count = np.zeros(example_img.shape)  # To count the non-zero entries for accurate averaging\n",
    "\n",
    "    selected_maps = []  # Initialize a list to store the paths of selected maps\n",
    "\n",
    "    # Randomly select one map per subject/split and accumulate\n",
    "    for split_id, map_paths in split_maps_paths.items():\n",
    "        selected_map_path = random.choice(map_paths)  # Randomly choose a map for the current split\n",
    "        selected_maps.append(selected_map_path)  # Store the selected map path for reference\n",
    "        \n",
    "        ####INCLUDE MASK TO GET ONLY BRAIN VALUES!!!! ######\n",
    "        \n",
    "        masked_data = apply_mask(selected_map_path, nifti_masker.mask_img_)\n",
    "        mask_indices = np.where(nifti_masker.mask_img_.get_fdata() > 0)\n",
    "\n",
    "        # Reconstruct the 3D volume for the current map's masked data\n",
    "        reconstructed_volume = np.zeros(example_img.shape)\n",
    "        reconstructed_volume[mask_indices] = masked_data\n",
    "\n",
    "        sum_of_masked_data += reconstructed_volume\n",
    "        mask_voxels_count[mask_indices] += 1\n",
    "\n",
    "    # Avoid division by zero\n",
    "    mask_voxels_count[mask_voxels_count == 0] = 1\n",
    "\n",
    "    # Compute the mean of accumulated data\n",
    "    averaged_map_data = sum_of_masked_data / mask_voxels_count\n",
    "    \n",
    "    #### NEED TO RECONSTRUCT AVERAGED_MAP_DATA INTO 3D TO SAVE THE NII FILE ####\n",
    "\n",
    "    # Create a new NIfTI image for the averaged map data and save it\n",
    "    averaged_map = nib.Nifti1Image(averaged_map_data, example_img.affine)\n",
    "    averaged_map_filename = f\"permuted_mean_group_accuracy_map_{iteration+1:03d}.nii\"\n",
    "    averaged_map_path = os.path.join(output_dir, averaged_map_filename)\n",
    "    averaged_map.to_filename(averaged_map_path)\n",
    "\n",
    "    end_time = time.time()  # Mark the end time of the iteration\n",
    "    duration = end_time - start_time  # Calculate the duration of this iteration\n",
    "\n",
    "    # Return iteration details, including timing and the mean group accuracy\n",
    "    return {\n",
    "        \"Iteration\": iteration + 1,\n",
    "        \"Duration (s)\": duration,\n",
    "        \"Selected Maps\": selected_maps,\n",
    "        \"Mean Group Acc\": np.mean(averaged_map_data)\n",
    "    }\n",
    "    \n",
    "    #print(f\"Saved permuted group accuracy map for iteration {iteration+1}\")\n",
    "    \n",
    "# Measure the total processing time\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Use ProcessPoolExecutor to run iterations in parallel\n",
    "iteration_timings = []\n",
    "\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    # Start all iterations and return futures\n",
    "    futures = [executor.submit(perform_iteration, iteration, output_dir, nifti_masker, split_maps_paths) for iteration in range(n_iterations)]\n",
    "    \n",
    "    # As each future completes, record its duration\n",
    "    for future in as_completed(futures):\n",
    "        iteration_timings.append(future.result())\n",
    "\n",
    "total_end_time = time.time()\n",
    "total_duration = total_end_time - total_start_time\n",
    "print(f\"Total processing time: {total_duration:.2f} seconds.\")\n",
    "\n",
    "# Add total processing time to the timings list\n",
    "iteration_timings.append({\"Iteration\": \"Total\", \"Duration (s)\": total_duration})\n",
    "\n",
    "# Save timings to a CSV file\n",
    "timings_file = os.path.join(output_dir, \"timings.csv\")\n",
    "with open(timings_file, 'w', newline='') as file:\n",
    "    # Define fieldnames that match the timing information\n",
    "    fieldnames = [\"Iteration\", \"Duration (s)\"]\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    # Exclude 'mean_group_acc' and 'Selected Maps' from the data to be written\n",
    "    for result in iteration_timings:\n",
    "        if \"Iteration\" in result and \"Duration (s)\" in result:\n",
    "            writer.writerow({key: result[key] for key in fieldnames})\n",
    "\n",
    "# Save the collected data to a CSV file, corrected for mean selected maps\n",
    "maps_csv_file_path = os.path.join(output_dir, \"null_distribution_group_mean.csv\")\n",
    "with open(maps_csv_file_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Iteration', 'Selected Maps', 'Mean Group Acc']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for result in iteration_timings:\n",
    "        if \"Selected Maps\" and \"Mean Group Acc\" in result:\n",
    "            # Process each path in selected_maps to extract only the last two parts\n",
    "            processed_selected_maps = [\n",
    "                '/'.join(path.split(os.sep)[-2:])  # Adjusted to include only the last two parts of path for context\n",
    "                for path in result['Selected Maps']\n",
    "            ]\n",
    "            # Convert the list of processed paths to a string\n",
    "            selected_maps_str = '|'.join(processed_selected_maps)\n",
    "            prepared_data = {\n",
    "                'Iteration': result['Iteration'],\n",
    "                'Selected Maps': selected_maps_str,\n",
    "                'Mean Group Acc': result['Mean Group Acc']\n",
    "            }\n",
    "            writer.writerow(prepared_data)\n",
    "\n",
    "print(f\"Timings saved to {timings_file}\")\n",
    "print(f\"Null distribution saved to {maps_csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "168f2564-41ec-4060-aac8-742eb848c009",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask_voxels_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmask_voxels_count\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mask_voxels_count' is not defined"
     ]
    }
   ],
   "source": [
    "sum_of_masked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2608d12f-fbbe-4157-b18c-b8872c505da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_distribution = \"/projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/ISPA_SearchLight_TB_permut/withinsubj_permut/permu_mean_group_acc_maps_test/null_distribution_group_mean.csv\"\n",
    "\n",
    "null_distribution_df = pd.read_csv(null_distribution)\n",
    "\n",
    "# Access the \"Mean Group Acc\" column\n",
    "null_distribution_df = null_distribution_df['Mean Group Acc']\n",
    "\n",
    "# Count the number of rows\n",
    "num_rows = null_distribution_df.count()\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "\n",
    "# check mean values of null distributions (should be close to 0.5)\n",
    "\n",
    "\n",
    "# Compute the mean of the \"Mean Group Acc\" column\n",
    "column_mean = null_distribution_df.mean()\n",
    "print(f\"Mean of 'Mean Group Acc': {column_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91280f63-7f22-4bd5-90d0-61a68c17adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_distribution = \"/projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/ISPA_SearchLight_TB_permut/withinsubj_permut/permu_mean_group_acc_maps/null_distribution_group_mean.csv\"\n",
    "\n",
    "null_distribution_df = pd.read_csv(null_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e06d8a2",
   "metadata": {},
   "source": [
    "# Generating figures of sinificant brain regions from SnPM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf153918",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = '/projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/snpm_batch_cluster_level'\n",
    "fname = '/projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/snpm_batch_cluster_level/lP_FDR+.img'\n",
    "\n",
    "#brain_nii = nb.load(result_dir + '/lP_FWE+.img')\n",
    "img = nb.load(fname)\n",
    "nb.save(img, fname.replace('.img', '.nii'))\n",
    "display = plotting.plot_glass_brain(None, display_mode='lyrz')\n",
    "color = 'r'\n",
    "display.add_contours(img, filled=True, levels=[1], colors=color)\n",
    "display.title('regions uncovered by ISPA, cluster-level FWE')\n",
    "#display.savefig(result_dir + '/{}_{}.png'.format(dataset_name, decoding_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02dd4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_snpm = '/projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/snpm_batch_cluster_level/SnPM_filtered.nii'\n",
    "cluster_snpm = nb.load(cluster_snpm)\n",
    "\n",
    "vmax = -np.log10(1 / 10000)  # ~= -np.log10(1 / n_perm)\n",
    "\n",
    "\n",
    "plotting.plot_stat_map(cluster_snpm,\n",
    "                       cut_coords=(-9, 0, 5, 10),\n",
    "                      title='SnPM FWE cluster mass', vmax=vmax, display_mode='x', cmap = \"Oranges\",\n",
    "                      black_bg=False, draw_cross = False, dim = 1, alpha=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86c3dff-5959-4cd8-ad5b-cb0aba232bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "cluster_snpm = '/projetos/PRJ1901_AMID/03_PROCS/TCT_FAPERJ_2023/Postnatal_Affect_Dataset/snpm_batch_cluster_level/SnPM_filtered.nii'\n",
    "cluster_snpm = nb.load(cluster_snpm)\n",
    "\n",
    "vmax = -np.log10(1 / 10000)  # ~= -np.log10(1 / n_perm)\n",
    "\n",
    "\n",
    "plotting.plot_stat_map(cluster_snpm,\n",
    "                       cut_coords=(-20,-15,-9,5),\n",
    "                     vmax=vmax, display_mode='z', cmap = \"Oranges\",\n",
    "                      black_bg=False, draw_cross = False, dim = 1, alpha=0.85)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
